{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install imageio\n",
    "!pip install git+https://github.com/tensorflow/docs"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-31T16:22:26.492018Z",
     "iopub.execute_input": "2022-07-31T16:22:26.492568Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imageio in /home/he/Projects/projects/.venv/lib/python3.10/site-packages (2.20.0)\r\n",
      "Requirement already satisfied: pillow>=8.3.2 in /home/he/Projects/projects/.venv/lib64/python3.10/site-packages (from imageio) (9.2.0)\r\n",
      "Requirement already satisfied: numpy in /home/he/Projects/projects/.venv/lib64/python3.10/site-packages (from imageio) (1.23.1)\r\n",
      "\u001B[33mWARNING: You are using pip version 21.2.3; however, version 22.2.1 is available.\r\n",
      "You should consider upgrading via the '/home/he/Projects/projects/.venv/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n",
      "Collecting git+https://github.com/tensorflow/docs\r\n",
      "  Cloning https://github.com/tensorflow/docs to /tmp/pip-req-build-1ihpd31j\r\n",
      "  Running command git clone -q https://github.com/tensorflow/docs /tmp/pip-req-build-1ihpd31j\r\n",
      "  Resolved https://github.com/tensorflow/docs to commit be563d905794ccc2e436b24ea519bc9e4d99b8ab\r\n",
      "Collecting astor\r\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\r\n",
      "Requirement already satisfied: absl-py in /home/he/Projects/projects/.venv/lib/python3.10/site-packages (from tensorflow-docs==0.0.0.dev0) (1.2.0)\r\n",
      "Requirement already satisfied: jinja2 in /home/he/Projects/projects/.venv/lib/python3.10/site-packages (from tensorflow-docs==0.0.0.dev0) (3.1.2)\r\n",
      "Requirement already satisfied: protobuf<3.20,>=3.12.0 in /home/he/Projects/projects/.venv/lib64/python3.10/site-packages (from tensorflow-docs==0.0.0.dev0) (3.19.4)\r\n",
      "Collecting pyyaml\r\n",
      "  Downloading PyYAML-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (682 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 682 kB 2.4 MB/s eta 0:00:01\r\n",
      "\u001B[?25hRequirement already satisfied: MarkupSafe>=2.0 in /home/he/Projects/projects/.venv/lib64/python3.10/site-packages (from jinja2->tensorflow-docs==0.0.0.dev0) (2.1.1)\r\n",
      "Building wheels for collected packages: tensorflow-docs\r\n",
      "  Building wheel for tensorflow-docs (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for tensorflow-docs: filename=tensorflow_docs-0.0.0.dev0-py3-none-any.whl size=180248 sha256=ad9ec53e3a3e572e839095577acf4d1a0821ed8f5b948cb86bb2fb9895bbb680\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-2k3a_4dd/wheels/86/0f/1e/3b62293c8ffd0fd5a49508e6871cdb7554abe9c62afd35ec53\r\n",
      "Successfully built tensorflow-docs\r\n",
      "Installing collected packages: pyyaml, astor, tensorflow-docs\r\n",
      "Successfully installed astor-0.8.1 pyyaml-6.0 tensorflow-docs-0.0.0.dev0\r\n",
      "\u001B[33mWARNING: You are using pip version 21.2.3; however, version 22.2.1 is available.\r\n",
      "You should consider upgrading via the '/home/he/Projects/projects/.venv/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import numpy as np\n",
    "import PIL\n",
    "from keras import layers\n",
    "import glob\n",
    "import imageio\n",
    "import time\n",
    "import pandas as pd\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2022-07-27T00:10:55.611441Z",
     "iopub.execute_input": "2022-07-27T00:10:55.612464Z",
     "iopub.status.idle": "2022-07-27T00:10:55.619928Z",
     "shell.execute_reply.started": "2022-07-27T00:10:55.612418Z",
     "shell.execute_reply": "2022-07-27T00:10:55.618815Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def read_image_dataset(path):\n",
    "    images = []\n",
    "    for dirpath, dirnames, filenames in os.walk(path):\n",
    "        for i in range(30000):\n",
    "            images.append(tf.io.read_file(os.path.join(path, filenames[i])))\n",
    "            \n",
    "    return images"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-27T00:10:59.068626Z",
     "iopub.execute_input": "2022-07-27T00:10:59.069098Z",
     "iopub.status.idle": "2022-07-27T00:10:59.078897Z",
     "shell.execute_reply.started": "2022-07-27T00:10:59.069055Z",
     "shell.execute_reply": "2022-07-27T00:10:59.077445Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "raw_images = read_image_dataset('../input/celeba-dataset/img_align_celeba/img_align_celeba/')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-27T00:11:01.265811Z",
     "iopub.execute_input": "2022-07-27T00:11:01.266185Z",
     "iopub.status.idle": "2022-07-27T00:16:57.903267Z",
     "shell.execute_reply.started": "2022-07-27T00:11:01.266152Z",
     "shell.execute_reply": "2022-07-27T00:16:57.902265Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def decode_images(raws):\n",
    "    output = []\n",
    "    for raw in raws:\n",
    "        output.append(tf.image.decode_image(raw, channels=1))\n",
    "    return output"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-27T00:23:33.795469Z",
     "iopub.execute_input": "2022-07-27T00:23:33.796097Z",
     "iopub.status.idle": "2022-07-27T00:23:33.801586Z",
     "shell.execute_reply.started": "2022-07-27T00:23:33.79606Z",
     "shell.execute_reply": "2022-07-27T00:23:33.800245Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "images = decode_images(raw_images)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-27T00:23:35.400846Z",
     "iopub.execute_input": "2022-07-27T00:23:35.401224Z",
     "iopub.status.idle": "2022-07-27T00:23:41.019723Z",
     "shell.execute_reply.started": "2022-07-27T00:23:35.401191Z",
     "shell.execute_reply": "2022-07-27T00:23:41.018737Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(len(images))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-27T00:24:26.381169Z",
     "iopub.execute_input": "2022-07-27T00:24:26.381533Z",
     "iopub.status.idle": "2022-07-27T00:24:26.387126Z",
     "shell.execute_reply.started": "2022-07-27T00:24:26.381497Z",
     "shell.execute_reply": "2022-07-27T00:24:26.3861Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def resize_images(images):\n",
    "    output = []\n",
    "    for image in images:\n",
    "        image = image / 255\n",
    "        output.append(tf.image.resize(image, [128, 128]))\n",
    "    return output"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-27T00:24:34.554887Z",
     "iopub.execute_input": "2022-07-27T00:24:34.55523Z",
     "iopub.status.idle": "2022-07-27T00:24:34.561322Z",
     "shell.execute_reply.started": "2022-07-27T00:24:34.5552Z",
     "shell.execute_reply": "2022-07-27T00:24:34.560359Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = resize_images(images)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-27T00:24:36.668873Z",
     "iopub.execute_input": "2022-07-27T00:24:36.669533Z",
     "iopub.status.idle": "2022-07-27T00:24:54.592754Z",
     "shell.execute_reply.started": "2022-07-27T00:24:36.669474Z",
     "shell.execute_reply": "2022-07-27T00:24:54.591536Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(len(dataset))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-27T00:34:40.647597Z",
     "iopub.execute_input": "2022-07-27T00:34:40.647931Z",
     "iopub.status.idle": "2022-07-27T00:34:40.653393Z",
     "shell.execute_reply.started": "2022-07-27T00:34:40.647902Z",
     "shell.execute_reply": "2022-07-27T00:34:40.652186Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "plt.imshow(dataset[1], cmap='gray')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-27T00:34:42.279434Z",
     "iopub.execute_input": "2022-07-27T00:34:42.280412Z",
     "iopub.status.idle": "2022-07-27T00:34:42.506102Z",
     "shell.execute_reply.started": "2022-07-27T00:34:42.280362Z",
     "shell.execute_reply": "2022-07-27T00:34:42.505199Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 31,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [31]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m plt\u001B[38;5;241m.\u001B[39mimshow(\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m, cmap\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgray\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-27T00:35:09.731193Z",
     "iopub.execute_input": "2022-07-27T00:35:09.73159Z",
     "iopub.status.idle": "2022-07-27T00:35:09.736061Z",
     "shell.execute_reply.started": "2022-07-27T00:35:09.731554Z",
     "shell.execute_reply": "2022-07-27T00:35:09.734947Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(dataset).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-27T00:34:57.74781Z",
     "iopub.execute_input": "2022-07-27T00:34:57.748172Z",
     "iopub.status.idle": "2022-07-27T00:35:00.311695Z",
     "shell.execute_reply.started": "2022-07-27T00:34:57.748141Z",
     "shell.execute_reply": "2022-07-27T00:35:00.31068Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(8*8*256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((8, 8, 256)))\n",
    "    assert model.output_shape == (None, 8, 8, 256)  # Note: None is the batch size\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 8, 8, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 16, 16, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    assert model.output_shape == (None, 32, 32, 32)\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(16, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    \n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 128, 128, 1)\n",
    "    \n",
    "    return model"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-27T00:35:12.985769Z",
     "iopub.execute_input": "2022-07-27T00:35:12.986149Z",
     "iopub.status.idle": "2022-07-27T00:35:13.00093Z",
     "shell.execute_reply.started": "2022-07-27T00:35:12.986119Z",
     "shell.execute_reply": "2022-07-27T00:35:12.999983Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "generator = make_generator_model()\n",
    "\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-27T00:35:15.167274Z",
     "iopub.execute_input": "2022-07-27T00:35:15.167634Z",
     "iopub.status.idle": "2022-07-27T00:35:22.199421Z",
     "shell.execute_reply.started": "2022-07-27T00:35:15.167601Z",
     "shell.execute_reply": "2022-07-27T00:35:22.198452Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                                     input_shape=[128, 128, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-27T00:35:24.990522Z",
     "iopub.execute_input": "2022-07-27T00:35:24.990986Z",
     "iopub.status.idle": "2022-07-27T00:35:25.004527Z",
     "shell.execute_reply.started": "2022-07-27T00:35:24.990937Z",
     "shell.execute_reply": "2022-07-27T00:35:25.003502Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "discriminator = make_discriminator_model()\n",
    "decision = discriminator(generated_image)\n",
    "print (decision)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-27T00:35:27.095788Z",
     "iopub.execute_input": "2022-07-27T00:35:27.096718Z",
     "iopub.status.idle": "2022-07-27T00:35:27.330643Z",
     "shell.execute_reply.started": "2022-07-27T00:35:27.096674Z",
     "shell.execute_reply": "2022-07-27T00:35:27.329564Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-27T00:35:29.229653Z",
     "iopub.execute_input": "2022-07-27T00:35:29.230832Z",
     "iopub.status.idle": "2022-07-27T00:35:29.236262Z",
     "shell.execute_reply.started": "2022-07-27T00:35:29.230785Z",
     "shell.execute_reply": "2022-07-27T00:35:29.235203Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-27T00:35:30.849708Z",
     "iopub.execute_input": "2022-07-27T00:35:30.850749Z",
     "iopub.status.idle": "2022-07-27T00:35:30.856791Z",
     "shell.execute_reply.started": "2022-07-27T00:35:30.850699Z",
     "shell.execute_reply": "2022-07-27T00:35:30.855761Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-27T00:35:32.245165Z",
     "iopub.execute_input": "2022-07-27T00:35:32.245542Z",
     "iopub.status.idle": "2022-07-27T00:35:32.250275Z",
     "shell.execute_reply.started": "2022-07-27T00:35:32.245496Z",
     "shell.execute_reply": "2022-07-27T00:35:32.249125Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-27T00:35:33.465504Z",
     "iopub.execute_input": "2022-07-27T00:35:33.46658Z",
     "iopub.status.idle": "2022-07-27T00:35:33.472501Z",
     "shell.execute_reply.started": "2022-07-27T00:35:33.46653Z",
     "shell.execute_reply": "2022-07-27T00:35:33.471531Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-27T00:35:35.917276Z",
     "iopub.execute_input": "2022-07-27T00:35:35.918032Z",
     "iopub.status.idle": "2022-07-27T00:35:35.925439Z",
     "shell.execute_reply.started": "2022-07-27T00:35:35.917992Z",
     "shell.execute_reply": "2022-07-27T00:35:35.924374Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "EPOCHS = 1000\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# You will reuse this seed overtime (so it's easier)\n",
    "# to visualize progress in the animated GIF)\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-27T00:35:37.9772Z",
     "iopub.execute_input": "2022-07-27T00:35:37.977564Z",
     "iopub.status.idle": "2022-07-27T00:35:37.983771Z",
     "shell.execute_reply.started": "2022-07-27T00:35:37.97753Z",
     "shell.execute_reply": "2022-07-27T00:35:37.982745Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      generated_images = generator(noise, training=True)\n",
    "\n",
    "      real_output = discriminator(images, training=True)\n",
    "      fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "      gen_loss = generator_loss(fake_output)\n",
    "      disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-27T00:35:40.069549Z",
     "iopub.execute_input": "2022-07-27T00:35:40.069893Z",
     "iopub.status.idle": "2022-07-27T00:35:40.077501Z",
     "shell.execute_reply.started": "2022-07-27T00:35:40.069862Z",
     "shell.execute_reply": "2022-07-27T00:35:40.076609Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def train(dataset, epochs):\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    for image_batch in dataset:\n",
    "      train_step(image_batch)\n",
    "\n",
    "    # Produce images for the GIF as you go\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,\n",
    "                             epoch + 1,\n",
    "                             seed)\n",
    "\n",
    "    # Save the model every 15 epochs\n",
    "    if (epoch + 1) % 15 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "  # Generate after the final epoch\n",
    "  display.clear_output(wait=True)\n",
    "  generate_and_save_images(generator,\n",
    "                           epochs,\n",
    "                           seed)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-27T00:35:42.776671Z",
     "iopub.execute_input": "2022-07-27T00:35:42.777673Z",
     "iopub.status.idle": "2022-07-27T00:35:42.785205Z",
     "shell.execute_reply.started": "2022-07-27T00:35:42.777623Z",
     "shell.execute_reply": "2022-07-27T00:35:42.784133Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  # Notice `training` is set to False.\n",
    "  # This is so all layers run in inference mode (batchnorm).\n",
    "  predictions = model(test_input, training=False)\n",
    "\n",
    "  fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "      plt.subplot(4, 4, i+1)\n",
    "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "      plt.axis('off')\n",
    "\n",
    "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-27T00:35:45.1138Z",
     "iopub.execute_input": "2022-07-27T00:35:45.114181Z",
     "iopub.status.idle": "2022-07-27T00:35:45.121911Z",
     "shell.execute_reply.started": "2022-07-27T00:35:45.114151Z",
     "shell.execute_reply": "2022-07-27T00:35:45.120805Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train(dataset, EPOCHS)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-27T00:35:50.195241Z",
     "iopub.execute_input": "2022-07-27T00:35:50.195656Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-26T21:05:08.749232Z",
     "iopub.execute_input": "2022-07-26T21:05:08.750645Z",
     "iopub.status.idle": "2022-07-26T21:05:08.877541Z",
     "shell.execute_reply.started": "2022-07-26T21:05:08.750598Z",
     "shell.execute_reply": "2022-07-26T21:05:08.87659Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def display_image(epoch_no):\n",
    "  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-26T21:05:10.343339Z",
     "iopub.execute_input": "2022-07-26T21:05:10.344009Z",
     "iopub.status.idle": "2022-07-26T21:05:10.348921Z",
     "shell.execute_reply.started": "2022-07-26T21:05:10.343972Z",
     "shell.execute_reply": "2022-07-26T21:05:10.347937Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "display_image(EPOCHS)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-26T21:05:11.927286Z",
     "iopub.execute_input": "2022-07-26T21:05:11.929874Z",
     "iopub.status.idle": "2022-07-26T21:05:11.955128Z",
     "shell.execute_reply.started": "2022-07-26T21:05:11.929836Z",
     "shell.execute_reply": "2022-07-26T21:05:11.954038Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "anim_file = 'dcgan.gif'\n",
    "\n",
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "  filenames = glob.glob('image*.png')\n",
    "  filenames = sorted(filenames)\n",
    "  for filename in filenames:\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)\n",
    "  image = imageio.imread(filename)\n",
    "  writer.append_data(image)\n",
    "\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-26T21:05:22.715008Z",
     "iopub.execute_input": "2022-07-26T21:05:22.715386Z",
     "iopub.status.idle": "2022-07-26T21:05:26.02732Z",
     "shell.execute_reply.started": "2022-07-26T21:05:22.715355Z",
     "shell.execute_reply": "2022-07-26T21:05:26.026111Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow_docs.vis.embed as embed\n",
    "embed.embed_file(anim_file)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-26T20:59:52.209717Z",
     "iopub.execute_input": "2022-07-26T20:59:52.210743Z",
     "iopub.status.idle": "2022-07-26T20:59:52.321736Z",
     "shell.execute_reply.started": "2022-07-26T20:59:52.210694Z",
     "shell.execute_reply": "2022-07-26T20:59:52.32065Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}